# Licensed to the .NET Foundation under one or more agreements.
# The .NET Foundation licenses this file to you under the MIT license.
# See the LICENSE file in the project root for more information.

"""
A 'foo.yaml' file stores a specification of the tests to run.
These may be generated by the `generate` command of `run_tests.py`, see documentation there.
"""

from dataclasses import dataclass, fields
from enum import Enum
from pathlib import Path
from typing import Any, cast, Iterable, Mapping, Optional, Sequence, Tuple, Type, Union

from overrides import overrides

from .collection_util import (
    combine_mappings,
    empty_mapping,
    find_only_or_only_matching,
    is_empty,
    optional_mapping,
)
from .option import map_option, non_null, optional_to_iter, option_or, option_or_3
from .parse_and_serialize import HexInt, load_yaml, SerializeMappings, write_yaml_file
from .score_spec import ScoreSpec
from .type_utils import doc_field, get_field_info_from_name, OrderedEnum, with_slots
from .util import (
    add_extension,
    assert_is_percent,
    get_existing_absolute_file_path,
    get_hostname,
    get_os,
    hex_no_0x,
    OS,
    remove_str_start,
    try_remove_str_end,
    try_remove_str_start,
)


@with_slots
@dataclass(frozen=True)
class GCPerfSimResult:
    """See `PrintResult` in GCPerfSim.cs"""

    seconds_taken: float
    final_total_memory_bytes: int
    # Indexed by generation (0-2)
    collection_counts: Tuple[int, int, int]
    # missing on older .NET versions
    final_heap_size_bytes: Optional[int] = None
    final_fragmentation_bytes: Optional[int] = None


@doc_field("memory_mb", "Size of the container in mebibytes.")
@doc_field("cpu_rate_hard_cap", "This allows fractional amounts, e.g. 2.5.")
@doc_field("image_name", "Not yet implemented. This would be the name of a docker container.")
@with_slots
@dataclass(frozen=True)
class TestConfigContainer:
    """
    Options for running the test in a container.
    A container is a cgroup, or a job object on windows.
    Docker containers are not yet implemented.
    """

    memory_mb: Optional[float] = None
    cpu_rate_hard_cap: Optional[float] = None
    image_name: Optional[str] = None

    def __post_init__(self) -> None:
        mb = self.memory_mb
        if mb is not None:
            assert 1 <= mb <= 100000
        cpu = self.cpu_rate_hard_cap
        if cpu is not None:
            assert 0 < cpu <= 1


@doc_field("complus_gcserver", "Set to true to use server GC.")
@doc_field("complus_gcconcurrent", "Set to true to allow background GCs.")
@doc_field("complus_gcgen0size", "gen0size in bytes. (decimal)")
@doc_field("complus_gcgen0maxbudget", "Max gen0 budget in bytes. (decimal)")
@doc_field(
    "complus_gcheapaffinitizeranges",
    """
On non-Windows, this should look like: 1,3,5,7-9,12
On Windows, this should include group numbers, like: 0:1,0:3,0:5,1:7-9,1:12
""",
)
@doc_field(
    "complus_gcheapcount",
    """
Number of heaps. (decimal)
Only has effect when complus_gcserver is set.
""",
)
@doc_field("complus_gcheaphardlimit", "Hard limit on heap size, in bytes. (decimal)")
@doc_field("complus_gclargepages", "Set to true to enable large pages.")
@doc_field("complus_gcnoaffinitize", "Set to true to prevent affinitizing GC threads to cpu cores.")
@doc_field("complus_gccpugroup", "Set to true to enable CPU groups.")
@doc_field("complus_gcnumaaware", "Set to false to disable NUMA-awareness in GC")
@doc_field(
    "complus_thread_useallcpugroups",
    "Set to true to automatically distribute threads across CPU Groups",
)
@doc_field(
    "complus_threadpool_forcemaxworkerthreads",
    "Overrides the MaxThreads setting for the ThreadPool worker pool",
)
@doc_field("complus_tieredcompilation", "Set to true to enable tiered compilation")
@doc_field(
    "container",
    """
Set to run the test in a container.
A container is a job object on Windows, or cgroups / docker container on non-Windows.
""",
)
@doc_field(
    "affinitize",
    """
If true, this will be run in a job object affinitized to a single core.
Only works on Windows.
See `run_in_job.c`'s `--affinitize` option.
""",
)
@doc_field(
    "memory_load_percent",
    "If set, the test runner will launch a second process that ensures "
    + "this percentage of the system's memory is consumed.",
)
@with_slots
@dataclass(frozen=True)
class Config:
    """
    Allows to set environment variables, and container and memory load options.
    WARN: Normally complus environment variables are specified in hexadecimal on the command line.
    But when specifying them in a yaml file, use decimal.
    """

    complus_gcserver: Optional[bool] = None
    complus_gcconcurrent: Optional[bool] = None
    # This is in bytes
    complus_gcgen0size: Optional[int] = None
    complus_gcgen0maxbudget: Optional[int] = None
    complus_gcheapaffinitizeranges: Optional[str] = None
    complus_gcheapcount: Optional[int] = None
    complus_gcheaphardlimit: Optional[int] = None
    complus_gclargepages: Optional[bool] = None
    complus_gcnoaffinitize: Optional[bool] = None
    complus_gccpugroup: Optional[bool] = None
    complus_gcnumaaware: Optional[bool] = None
    complus_thread_useallcpugroups: Optional[bool] = None
    complus_threadpool_forcemaxworkerthreads: Optional[int] = None
    complus_tieredcompilation: Optional[bool] = None
    container: Optional[TestConfigContainer] = None
    affinitize: Optional[bool] = None
    memory_load_percent: Optional[float] = None
    # Remember to update _parse_test_config when adding a new field

    def __post_init__(self) -> None:
        if self.complus_gcheapaffinitizeranges is not None:
            _parse_heap_affinitize_ranges(self.complus_gcheapaffinitizeranges)
        if self.memory_load_percent is not None:
            assert_is_percent(self.memory_load_percent)

    @staticmethod
    def serialize_mappings() -> SerializeMappings:
        def f(x: Optional[int]) -> Optional[HexInt]:
            return map_option(x, HexInt)

        return {field.name: f for field in fields(Config) if field.type is int}

    def to_str_pretty(self) -> str:
        return ", ".join(
            # NOTE: not using isinstance(value, int) because apparently bools are ints
            f"{field.name}={hex(value) if field.type is int else str(value)}"
            for field in fields(Config)
            for value in (getattr(self, field.name),)
            if value is not None
        )


@with_slots
@dataclass(frozen=True)
class HeapAffinitizeRange:
    group: Optional[int]
    # both inclusive
    lo: int
    hi: int

    def __post_init__(self) -> None:
        assert self.lo <= self.hi


@with_slots
@dataclass(frozen=True)
class HeapAffinitizeRanges:
    ranges: Sequence[HeapAffinitizeRange]


def _parse_heap_affinitize_ranges(s: str) -> HeapAffinitizeRanges:
    # Based on 'ParseGCHeapAffinitizeRanges' in gcconfig.cpp
    # The cpu index ranges is a comma separated list of indices or ranges of indices (e.g. 1-5).
    # Example 1,3,5,7-9,12
    parts = s.split(",")
    ranges = [_parse_heap_affinitize_range(part) for part in parts]
    _assert_sorted_and_non_overlapping(ranges)
    return HeapAffinitizeRanges(ranges)


def _assert_sorted_and_non_overlapping(ranges: Sequence[HeapAffinitizeRange]) -> None:
    prev = -1
    for r in ranges:
        assert r.lo > prev
        prev = r.hi


def _parse_heap_affinitize_range(s: str) -> HeapAffinitizeRange:
    if ":" in s:
        l, r = s.split(":", 1)
        return _parse_heap_affinitize_range_after_group(int(l), r)
    else:
        return _parse_heap_affinitize_range_after_group(None, s)


def _parse_heap_affinitize_range_after_group(group: Optional[int], s: str) -> HeapAffinitizeRange:
    if "-" in s:
        l, r = s.split("-", 1)
        return HeapAffinitizeRange(group=group, lo=int(l), hi=int(r))
    else:
        x = int(s)
        return HeapAffinitizeRange(group=group, lo=x, hi=x)


# Combined CommonConfig and individual test's config
@with_slots
@dataclass(frozen=True)
class TestConfigCombined:
    cfg: Config

    @property
    def container(self) -> Optional[TestConfigContainer]:
        return self.cfg.container

    @property
    def affinitize(self) -> Optional[bool]:
        return self.cfg.affinitize

    @property
    def complus_gcheapcount(self) -> Optional[int]:
        return self.cfg.complus_gcheapcount

    @property
    def complus_gcserver(self) -> Optional[bool]:
        return self.cfg.complus_gcserver

    @property
    def memory_load_percent(self) -> Optional[float]:
        return self.cfg.memory_load_percent

    def env(self, core_root: Optional[Path]) -> Mapping[str, str]:
        cfg = self.cfg

        def od(name: str, v: Optional[int]) -> Mapping[str, str]:
            return optional_mapping(name, map_option(v, hex_no_0x))

        def ob(name: str, v: Optional[bool]) -> Mapping[str, str]:
            return optional_mapping(name, map_option(v, lambda b: str(int(b))))

        return combine_mappings(
            empty_mapping() if core_root is None else {"CORE_ROOT": str(core_root)},
            ob("COMPlus_gcServer", cfg.complus_gcserver),
            ob("COMPlus_gcConcurrent", cfg.complus_gcconcurrent),
            od("COMPlus_GCgen0size", cfg.complus_gcgen0size),
            od("COMPlus_GCGen0MaxBudget", cfg.complus_gcgen0maxbudget),
            optional_mapping("COMPlus_GCHeapAffinitizeRanges", cfg.complus_gcheapaffinitizeranges),
            od("COMPlus_GCHeapCount", cfg.complus_gcheapcount),
            od("COMPlus_GCHeapHardLimit", cfg.complus_gcheaphardlimit),
            ob("COMPlus_GCLargePages", cfg.complus_gclargepages),
            ob("COMPlus_GCNoAffinitize", cfg.complus_gcnoaffinitize),
            ob("COMPlus_GCCpuGroup", cfg.complus_gccpugroup),
            ob("COMPlus_GCNumaAware", cfg.complus_gcnumaaware),
            ob("COMPlus_Thread_UseAllCpuGroups", cfg.complus_thread_useallcpugroups),
            od(
                "COMPlus_ThreadPool_ForceMaxWorkerThreads",
                cfg.complus_threadpool_forcemaxworkerthreads,
            ),
            ob("COMPlus_TieredCompilation", cfg.complus_tieredcompilation),
        )


@with_slots
@dataclass(frozen=True)
class PartialConfigAndName:
    name: str
    config: Config

    def to_tuple(self) -> Tuple[str, Config]:
        return self.name, self.config


@with_slots
@dataclass(frozen=True)
class FullConfigAndName:
    name: str
    config: TestConfigCombined

    @property
    def as_partial(self) -> PartialConfigAndName:
        return PartialConfigAndName(self.name, self.config.cfg)


@doc_field("none", "Do not collect any trace events.")
@doc_field("gc", "Collect normal GC events.")
@doc_field("verbose", "Collect verbose GC events, which includes join events.")
@doc_field("cpu_samples", "Collect all of the above, and CPU samples.")
@doc_field(
    "cswitch", "Collect all of the above, and CSwitch events on Windows. No effect on Linux."
)
class CollectKind(OrderedEnum):
    none = 0
    gc = 1
    verbose = 2
    cpu_samples = 3
    cswitch = 4


def doc_enum(e: Type[Enum]) -> str:
    def part(member: str) -> Optional[str]:
        info = get_field_info_from_name(e, member)
        return None if info.hidden else f"{member}: {info.doc}"

    return "\n".join(p for member in e for p in optional_to_iter(part(member.name)))


@with_slots
@dataclass(frozen=True)
class LogOptions:
    """
    Options for enabling 'dprintf' statements from gc.cpp.
    You'll need to modify coreclr too for this to work.
    This slows the process down, so not recommended for performance testing.
    """

    file_size_mb: int


@doc_field(
    "collect",
    f"""
    Kind of events to collect.
    Defaults to 'gc'.

    {doc_enum(CollectKind)}
    """,
)
@doc_field(
    "default_iteration_count",
    """
    Number of times to run the same test combination.
    "Defaults to 1.
    "Without this you will not get stdev.
    """,
)
@doc_field(
    "default_min_seconds",
    """
    If a test is over in less than this many seconds, the test runner will throw an exception.
    This ensures that tests have sufficient data for performance analysis.
    May be overridden by Benchmark#min_seconds
    """,
)
@doc_field(
    "default_max_seconds",
    """
    The test runner will stop a process that goes longer than this and fail.
    May be overridden by Benchmark#max_seconds.
    """,
)
@doc_field(
    "max_trace_size_gb",
    """
    If the trace exceeds this size, old events will be discarded.
    Defaults to 1.
    """,
)
@doc_field(
    "dotnet_path",
    """
    Custom 'dotnet' path to use when building.
    Does not affect running.
    """,
)
@doc_field(
    "dotnet_trace_path",
    """
Set this in case dotnet-trace is not in PATH.
Useful for tests that must be run as super user.
""",
)
@doc_field(
    "dotnet_trace_buffersize_mb",
    """
Value to pass to `--buffersize` argument of dotnet-trace, in MB.
Default is dotnet-trace's default, currently 256MB.
""",
)
@doc_field(
    "always_use_dotnet_trace",
    """
Always use dotnet-trace to collect traces, even on Windows where PerfView is the default.
Has no effect on non-Windows.
Has no effect if `collect` is `none`.
""",
)
@doc_field("log", "Options for enabling dprintf logging", hidden=True)
@with_slots
@dataclass(frozen=True)
class BenchOptions:
    # Not putting the default (CollectKind.gc) here
    # as that would mean the property would be created when serializing.
    collect: Optional[CollectKind] = None
    # Defaults to 1
    default_iteration_count: Optional[int] = None
    default_min_seconds: Optional[float] = None
    default_max_seconds: Optional[float] = None
    max_trace_size_gb: Optional[float] = None
    dotnet_path: Optional[Path] = None
    dotnet_trace_path: Optional[Path] = None
    dotnet_trace_buffersize_mb: Optional[int] = None
    always_use_dotnet_trace: Optional[bool] = None
    log: Optional[LogOptions] = None

    def __post_init__(self) -> None:
        assert self.default_iteration_count is None or self.default_iteration_count >= 1

    @property
    def get_collect(self) -> CollectKind:
        return option_or(self.collect, CollectKind.gc)


class AllocType(Enum):
    simple = 0
    reference = 1


class TestKind(Enum):
    time = 0
    highSurvival = 1


# Not documenting fields here as GCPerfSim should do that.
@doc_field("tc", None)
@doc_field("tagb", None)
@doc_field("tlgb", None)
@doc_field("totalMins", None)
@doc_field("lohar", None)
@doc_field("sohsi", None)
@doc_field("lohsi", None)
@doc_field("sohpi", None)
@doc_field("lohpi", None)
@doc_field("sohfi", None)
@doc_field("lohfi", None)
@doc_field("allocType", None)
@doc_field("testKind", None)
@with_slots
@dataclass(frozen=True)
class GCPerfSimArgs:
    """
    Represents the arguments to GCPerfSim.
    Read the GCPerfSim source for documentation.
    """

    tc: int
    tagb: float
    tlgb: float
    totalMins: Optional[float] = None
    lohar: int = 0
    sohsi: int = 0
    lohsi: int = 0
    sohpi: int = 0
    lohpi: int = 0
    sohfi: int = 0
    lohfi: int = 0
    allocType: AllocType = AllocType.reference
    testKind: TestKind = TestKind.time

    def to_map(self) -> Mapping[str, str]:
        return {
            "-tc": str(self.tc),
            "-tagb": str(self.tagb),
            "-tlgb": str(self.tlgb),
            **(empty_mapping() if self.totalMins is None else {"totalMins": str(self.totalMins)}),
            "-lohar": str(self.lohar),
            "-sohsi": str(self.sohsi),
            "-lohsi": str(self.lohsi),
            "-sohpi": str(self.sohpi),
            "-lohpi": str(self.lohpi),
            "-sohfi": str(self.sohfi),
            "-lohfi": str(self.lohfi),
            "-allocType": self.allocType.name,
            "-testKind": self.testKind.name,
        }

    def to_seq(self) -> Sequence[str]:
        return [x for pair in self.to_map().items() for x in pair]

    def to_str(self) -> str:
        return " ".join(self.to_seq())


@doc_field("executable", "Path or key into 'paths' from the BenchFile.\nDefaults to \"GCPerfSim\".")
@doc_field(
    "arguments",
    "Command line arguments to pass to the executable.\n"
    "For GCPerfSim, you can also specify GCPerfSimArgs, "
    "and it will be converted to a string for you.",
)
@doc_field("iteration_count", "Defaults to options.default_iteration_count")
@doc_field("min_seconds", "Defaults to options.default_min_seconds")
@doc_field("max_seconds", "Defaults to options.default_max_seconds")
@doc_field("only_configs", "Only run the test against configs with one of the specified names.")
@with_slots
@dataclass(frozen=True)
class Benchmark:
    executable: Optional[str] = None
    arguments: Optional[Union[str, GCPerfSimArgs]] = None
    iteration_count: Optional[int] = None
    min_seconds: Optional[float] = None
    max_seconds: Optional[float] = None
    only_configs: Optional[Sequence[str]] = None

    @property
    def arguments_list(self) -> Sequence[str]:
        if self.arguments is None:
            return ()
        elif isinstance(self.arguments, str):
            return self.arguments.split()
        else:
            return self.arguments.to_seq()

    def get_argument(self, name: str) -> Optional[str]:
        args = self.arguments_list
        for i, arg in enumerate(args):
            if arg == name:
                return args[i + 1]
        return None

    @property
    def get_executable(self) -> str:
        return option_or(self.executable, "GCPerfSim")

    def executable_and_arguments(self) -> str:
        ex = self.get_executable
        return ex if self.arguments is None else f"{ex} {self.arguments}"

    def __post_init__(self) -> None:
        assert self.iteration_count is None or self.iteration_count >= 1


@with_slots
@dataclass(frozen=True)
class BenchmarkAndName:
    name: str
    benchmark: Benchmark


class Architecture(Enum):
    amd64 = 0
    x86 = 1
    arm64 = 2
    arm32 = 3


class Bitness(Enum):
    bit32 = 0
    bit64 = 1

    @property
    def to_int(self) -> int:
        return {Bitness.bit32: 32, Bitness.bit64: 64}[self]

    @overrides
    def __str__(self) -> str:
        return f"{self.to_int}-bit"


# TODO:MOVE
def get_architecture_bitness(a: Architecture) -> Bitness:
    return {
        Architecture.amd64: Bitness.bit64,
        Architecture.x86: Bitness.bit32,
        Architecture.arm64: Bitness.bit64,
        Architecture.arm32: Bitness.bit32,
    }[a]


def get_this_machines_architecture() -> Architecture:
    from platform import machine

    m = machine()
    if m in ("AMD64", "x86_64"):
        return Architecture.amd64
    elif m == "armv71":
        return Architecture.arm64
    else:
        raise Exception(f"TODO: Fill in get_this_machines_architecture() for {m}")


@doc_field(
    "self_contained",
    """
    If this is set, benchmark executables should be self-contained.
    Then core_root and repo_path should not be set.
    """,
)
@doc_field(
    "core_root",
    """
    Path to a Core_Root directory built from coreclr.
    (Does not need to still be located inside a coreclr repository.)
    """,
)
@doc_field(
    "exact_path",
    """
    Path to the corerun executable.
    Generally prefer 'core_root' to this.
    """,
)
@doc_field(
    "repo_path",
    """
    Instead of specifying Core_Root, you could specify the path to the repository.
    Core_Root will be the default location of a release build.

    When running on a remote machine, the coreclr path must already exist on that machine.
    It should be at the same path in every machine being tested.
    Or, it may be a UNC path.
    """,
)
@doc_field(
    "commit_hash",
    """
    Optional; git commit hash that Core_Root was built from.
    On Windows, if SigCheck was installed,
    the test runner will verify that CoreRun.exe was tagged with this hash.
    On non-Windows this is just for information.
    """,
)
@doc_field(
    "architecture",
    """
    On Windows, if SigCheck was installed, the test runner will verify that
    CoreRun.exe has the correct bitness corresponding to this architecture.
    On non-Windows this is just for information.
    """,
)
@with_slots
@dataclass(frozen=True)
class CoreclrSpecifier:
    self_contained: Optional[bool] = None
    # Path to CORE_ROOT directory
    core_root: Optional[Path] = None
    # Repository path
    repo_path: Optional[Path] = None
    exact_path: Optional[Path] = None
    commit_hash: Optional[str] = None
    architecture: Optional[Architecture] = None

    def __post_init__(self) -> None:
        assert (
            self.self_contained != False
        ), "Instead of setting self_contained: false, just don't specify it"

        assert _exactly_one_of(
            self.self_contained is not None,
            self.repo_path is not None,
            self.core_root is not None,
            self.exact_path is not None,
        ), (
            "In 'coreclr:', exactly one of "
            "'self_contained', 'core_root', and 'repo_path' should be specified."
        )

    def get_architecture(self) -> Architecture:
        return (
            self.architecture if self.architecture is not None else get_this_machines_architecture()
        )


def _exactly_one_of(a: bool, b: bool, c: bool, d: bool) -> bool:
    return a + b + c + d == 1


@with_slots
@dataclass(frozen=True)
class CoreclrAndName:
    name: str
    coreclr: CoreclrSpecifier


@doc_field("name", "Name of the property we are testing different values for.")
@doc_field(
    "default_values",
    "Value that coreclr would use without an explicit config.\nKey is a coreclr name.",
)
@with_slots
@dataclass(frozen=True)
class ConfigsVaryBy:
    name: str
    default_values: Optional[Mapping[str, float]] = None


@with_slots
@dataclass(frozen=True)
class _MachinesFile:
    machines: Sequence[str]


@with_slots
@dataclass(frozen=True)
class Machine:
    name: str

    @property
    def is_this_machine(self) -> bool:
        return self.name == get_hostname()


def get_this_machine() -> Machine:
    return Machine(get_hostname())


MACHINE_DOC = """
The `--machine` argument can take multiple arguments like `name:machinea name:machineb`.
It can also take `file:C:/bench/machines.yaml`, where that file should look like:

machines:
  - machinea
  - machineb
  
Each name should be the name of a machine on your network.
"""

MAX_ITERATIONS_FOR_ANALYZE_DOC = """
Only analyze this many test iterations even when more are available.
This will speed up analysis.
"""

MAX_ITERATIONS_FOR_RUN_DOC = """
Only run at most this many iterations of a test,
even when 'default_iterations' or 'iterations' specifies a higher number.

If you do this, you'll have to specify '--max-iterations' again when analyzing the test results.
"""


def parse_machines_arg(machine_args: Optional[Sequence[str]]) -> Sequence[Machine]:
    if machine_args is None:
        return (get_this_machine(),)

    def get_machines(m: str) -> Sequence[Machine]:
        if m == "this":
            return (get_this_machine(),)

        file = try_remove_str_start(m, "file:")
        if file is not None:
            return [
                Machine(m)
                for m in load_yaml(_MachinesFile, get_existing_absolute_file_path(file)).machines
            ]
        else:
            return (Machine(remove_str_start(m, "name:")),)

    return [x for m in machine_args for x in get_machines(m)]


@with_slots
@dataclass(frozen=True)
class SingleTestCombination:
    machine: Machine
    coreclr: CoreclrAndName
    config: PartialConfigAndName
    benchmark: BenchmarkAndName

    @property
    def machine_name(self) -> str:
        return self.machine.name

    @property
    def coreclr_name(self) -> str:
        return self.coreclr.name

    @property
    def config_name(self) -> str:
        return self.config.name

    @property
    def benchmark_name(self) -> str:
        return self.benchmark.name

    @property
    def name(self) -> str:
        return (
            f"{self.machine_name}__{self.coreclr_name}__{self.config_name}__{self.benchmark_name}"
        )


@with_slots
@dataclass(frozen=True)
class TestRunStatus:
    test: SingleTestCombination
    success: bool
    process_id: int
    seconds_taken: float
    stdout: str
    # This will be missing if the test run was not GCPerfSim
    gcperfsim_result: Optional[GCPerfSimResult] = None
    # This will be missing if 'collect' was specified as 'none' in BenchOPtions
    trace_file_name: Optional[
        str
    ] = None  # File should be stored in the same directory as test status


@with_slots
@dataclass(frozen=True)
class PartialTestCombination:
    machine: Optional[Machine] = None
    coreclr_and_name: Optional[CoreclrAndName] = None
    config_and_name: Optional[PartialConfigAndName] = None
    benchmark_and_name: Optional[BenchmarkAndName] = None

    @property
    def machine_name(self) -> Optional[str]:
        return None if self.machine is None else self.machine.name

    @property
    def coreclr_name(self) -> Optional[str]:
        return None if self.coreclr_and_name is None else self.coreclr_and_name.name

    @property
    def config(self) -> Optional[Config]:
        return None if self.config_and_name is None else self.config_and_name.config

    @property
    def config_name(self) -> Optional[str]:
        return None if self.config_and_name is None else self.config_and_name.name

    @property
    def benchmark(self) -> Optional[Benchmark]:
        return None if self.benchmark_and_name is None else self.benchmark_and_name.benchmark

    @property
    def benchmark_name(self) -> Optional[str]:
        return None if self.benchmark_and_name is None else self.benchmark_and_name.name

    @property
    def name(self) -> str:
        parts: Sequence[str] = (
            *optional_to_iter(self.machine_name),
            *optional_to_iter(self.coreclr_name),
            *optional_to_iter(self.config_name),
            *optional_to_iter(self.benchmark_name),
        )
        return "only test" if is_empty(parts) else "__".join(parts)


class Vary(Enum):
    machine = 0
    coreclr = 1
    config = 2
    benchmark = 3


VARY_DOC = """
Kind of thing we want to compare.
For example, if we vary coreclr, "
we'll show one diff for each combination of config and benchmark.
Defaults to the bench file's specified 'vary'.
"""


@doc_field("comment", "(ignored)")
@doc_field("vary", "Preferred property to vary when using `py . diff`")
@doc_field(
    "configs_vary_by",
    """
This is mostly set just for information.
When there are many configs, this describes the one property that is changing.
""",
)
@doc_field("coreclrs", "Mapping from an (arbitrary) coreclr name to its specifier.")
@doc_field(
    "paths",
    """
Mapping of shorthand names for paths.
If the 'executable' field of a Benchmark is a key in this mapping,
it will be replaced with the corresponding value.
""",
)
@doc_field("options", "Additional options that apply to every test.")
@doc_field(
    "common_config",
    """
Config properties common to all configs.
Properties set here should not overlap with anything in 'configs'.
If omitted, the common config is empty.
""",
)
@doc_field(
    "configs",
    """
Mapping from an (arbitrary) config name to the config.
Unlike coreclrs and benchmarks, this section is optional.
If omitted, common_config will be used.
""",
)
@doc_field("benchmarks", "Mapping from an (arbitrary) benchmark name to the benchmark.")
@doc_field("scores", "Mapping from an (arbitrary) score name to its specifier.")
@with_slots
@dataclass(frozen=True)
class BenchFile:
    comment: Optional[str] = None
    vary: Optional[Vary] = None
    configs_vary_by: Optional[ConfigsVaryBy] = None
    coreclrs: Mapping[str, CoreclrSpecifier] = empty_mapping()
    paths: Optional[Mapping[str, Path]] = None  # Maps name to path
    options: BenchOptions = BenchOptions()
    common_config: Optional[Config] = None
    configs: Optional[Mapping[str, Config]] = None
    benchmarks: Mapping[str, Benchmark] = empty_mapping()
    scores: Optional[Mapping[str, ScoreSpec]] = None

    def __post_init__(self) -> None:
        assert not is_empty(self.coreclrs), "Benchfile must have at least one coreclr"
        assert not is_empty(self.benchmarks), "Benchfile must have at least one benchmark"
        assert self.configs is None or not is_empty(self.configs)

    @property
    def coreclrs_and_names(self) -> Sequence[CoreclrAndName]:
        return [CoreclrAndName(k, v) for k, v in self.coreclrs.items()]

    @property
    def partial_configs_and_names(self) -> Sequence[PartialConfigAndName]:
        if self.configs is None:
            return (PartialConfigAndName("only_config", Config()),)
        else:
            return [PartialConfigAndName(k, v) for k, v in self.configs.items()]

    @property
    def full_configs_and_names(self) -> Sequence[FullConfigAndName]:
        return [
            FullConfigAndName(cn.name, combine_test_configs(self.common_config, cn.config))
            for cn in self.partial_configs_and_names
        ]

    @property
    def benchmarks_and_names(self) -> Sequence[BenchmarkAndName]:
        return [BenchmarkAndName(k, v) for k, v in self.benchmarks.items()]


@with_slots
@dataclass(frozen=True)
class BenchFileAndPath:
    content: BenchFile
    path: Path


def _split_unc_path(s: str) -> Tuple[str, str]:
    unc_path = remove_str_start(s, "\\\\")
    parts = unc_path.split("\\", maxsplit=1)
    assert len(parts) == 2
    return cast(Tuple[str, str], tuple(parts))


# machine=None means this machine
def change_path_machine(path: Path, machine: Machine) -> Path:
    s = str(path)
    if s.startswith("\\\\"):
        # It's a UNC path -- replace the machine name
        rest = _split_unc_path(s)[1]
        if machine is None:
            root = {OS.posix: "", OS.windows: "C:"}[get_os()]
        else:
            root = f"//{machine.name}"
        return Path(f"{root}/{rest}")
    elif machine.is_this_machine:
        # Not changing machine
        return path
    elif s[1:].startswith(":\\"):
        # Windows drive
        if s[0] != "C":
            raise Exception("TODO: Accessing a non-'C' drive via UNC path?")
        rest = remove_str_start(s, "C:\\")
        return Path(f"//{machine.name}/{rest}")
    else:
        raise Exception("TODO: UNC path to a non-windows path?")


def out_dir_for_bench_yaml(bench_file: Path, machine: Machine) -> Path:
    return add_extension(change_path_machine(bench_file, machine), "out")


def parse_bench_file(path: Path) -> BenchFileAndPath:
    return BenchFileAndPath(load_yaml(BenchFile, path), path)


@with_slots
@dataclass(frozen=True)
class TestResult:
    test_status_path: Optional[Path] = None
    trace_path: Optional[Path] = None

    def __post_init__(self) -> None:
        assert self.test_status_path is not None or self.trace_path is not None
        assert self.test_status_path is None or self.test_status_path.name.endswith(".yaml")
        assert self.trace_path is None or is_trace_path(self.trace_path)

    def load_test_status(self) -> Optional[TestRunStatus]:
        return map_option(self.test_status_path, load_test_status)

    @property
    def trace_or_test_status_path(self) -> Path:
        return non_null(option_or(self.trace_path, self.test_status_path))

    @property
    def test_status_or_trace_path(self) -> Path:
        return non_null(option_or(self.test_status_path, self.trace_path))

    def __str__(self) -> str:
        return str(self.test_status_or_trace_path)


class TraceKind(Enum):
    Etl = 0
    Nettrace = 1
    Perfcollect = 2


def is_trace_path(trace_path: Path) -> bool:
    return _try_get_trace_kind(trace_path) is not None


def get_trace_kind(trace_path: Path) -> TraceKind:
    kind = _try_get_trace_kind(trace_path)
    assert kind is not None, f"Unexpected trace file {trace_path}"
    return kind


def _try_get_trace_kind(trace_path: Path) -> Optional[TraceKind]:
    name = trace_path.name
    if name.endswith(".etl"):
        return TraceKind.Etl
    elif name.endswith(".nettrace"):
        return TraceKind.Nettrace
    elif name.endswith(".trace.zip"):
        return TraceKind.Perfcollect
    else:
        return None


def load_test_status(path: Path) -> TestRunStatus:
    return load_yaml(TestRunStatus, path)


class TestPaths:
    out_path_base: Path

    def __init__(self, base: Path):
        self.out_path_base = base

    def add_ext(self, ext: str) -> Path:
        return add_extension(self.out_path_base, ext)

    @property
    def test_status_path(self) -> Path:
        return add_extension(self.out_path_base, "yaml")

    def exists(self) -> bool:
        return self.test_status_path.exists()

    def load_test_status(self) -> TestRunStatus:
        return load_yaml(TestRunStatus, self.test_status_path)

    def to_test_result(self) -> TestResult:
        return TestResult(
            test_status_path=self.test_status_path,
            trace_path=self.load_trace_file_path_if_success(),
        )

    def load_trace_file_path_if_success(self) -> Optional[Path]:
        test_status = self.load_test_status()
        if test_status.success and test_status.trace_file_name is not None:
            return self.out_path_base.parent / test_status.trace_file_name
        else:
            return None

    def trace_file_path(self, test_status: TestRunStatus) -> Optional[Path]:
        return map_option(test_status.trace_file_name, lambda n: self.out_path_base.parent / n)

    def write_test_status(self, test_status: TestRunStatus) -> None:
        write_yaml_file(self.test_status_path, test_status)


@with_slots
@dataclass(frozen=True)
class SingleTestToRun:
    bench_file: BenchFile
    test: SingleTestCombination
    iteration: int
    # Running the test should write foo.etl, foo.yaml, and possibly others (e.g. log files)
    out: TestPaths

    @property
    def coreclr_name(self) -> str:
        return self.test.coreclr_name

    @property
    def coreclr(self) -> CoreclrSpecifier:
        return self.test.coreclr.coreclr

    @property
    def config_name(self) -> str:
        return self.test.config_name

    @property
    def config(self) -> TestConfigCombined:
        return TestConfigCombined(self.test.config.config)

    @property
    def benchmark_name(self) -> str:
        return self.test.benchmark_name

    @property
    def benchmark(self) -> Benchmark:
        return self.test.benchmark.benchmark


def iter_test_combinations(
    bench_file: BenchFile, machines: Sequence[Machine]
) -> Iterable[SingleTestCombination]:
    for machine in machines:
        for coreclr in bench_file.coreclrs_and_names:
            for config in bench_file.partial_configs_and_names:
                for benchmark in bench_file.benchmarks_and_names:
                    yield SingleTestCombination(machine, coreclr, config, benchmark)


def iter_tests_to_run(
    bench: BenchFileAndPath,
    machine: Machine,
    max_iterations: Optional[int],
    out_dir: Optional[Path],
) -> Iterable[SingleTestToRun]:
    bench_file = bench.content
    for t in iter_test_combinations(bench.content, (machine,)):
        if (
            t.benchmark.benchmark.only_configs is None
            or t.config_name in t.benchmark.benchmark.only_configs
        ):
            for i, out_paths in enumerate(
                get_test_paths_for_each_iteration(bench, t, max_iterations, out_dir)
            ):
                yield SingleTestToRun(
                    bench_file=bench_file,
                    test=SingleTestCombination(
                        machine=machine,
                        coreclr=t.coreclr,
                        config=PartialConfigAndName(
                            name=t.config_name,
                            config=combine_test_configs(
                                bench_file.common_config, t.config.config
                            ).cfg,
                        ),
                        benchmark=t.benchmark,
                    ),
                    iteration=i,
                    out=out_paths,
                )


def get_iteration_count(
    bench: BenchFile, benchmark: Benchmark, max_iterations: Optional[int]
) -> int:
    assert (
        benchmark.iteration_count != 0
        and bench.options.default_iteration_count != 0
        and max_iterations != 0
    )
    i = option_or_3(benchmark.iteration_count, bench.options.default_iteration_count, 1)
    return min(i, max_iterations) if max_iterations is not None else i


# Returns a TestPaths for each iteration
def get_test_paths_for_each_iteration(
    bench: BenchFileAndPath,
    t: SingleTestCombination,
    max_iterations: Optional[int],
    out_dir: Optional[Path] = None,
) -> Sequence[TestPaths]:
    n_iters = get_iteration_count(bench.content, t.benchmark.benchmark, max_iterations)
    return [get_test_path(bench, t, i, out_dir) for i in range(n_iters)]


def get_test_path(
    bench: BenchFileAndPath,
    t: SingleTestCombination,
    iteration: int,
    out_dir: Optional[Path] = None,
) -> TestPaths:
    out = out_dir_for_bench_yaml(bench.path, t.machine) if out_dir is None else out_dir
    return TestPaths(out / f"{t.coreclr.name}__{t.config.name}__{t.benchmark.name}__{iteration}")


def combine_test_configs(
    common_config: Optional[Config], named_config: Config
) -> TestConfigCombined:
    if common_config is None:
        return TestConfigCombined(named_config)
    else:
        # Ensure no overlap
        def get_value(field_name: str) -> Any:
            from_common = getattr(common_config, field_name)
            from_named = getattr(named_config, field_name)
            if from_common is None:
                return getattr(named_config, field_name)
            else:
                assert (
                    from_named is None
                ), f"Overrides {field_name} (common_config: {from_common}, specified: {from_named})"
                return from_common

        return TestConfigCombined(Config(*(get_value(f.name) for f in fields(Config))))


def get_coreclr(bench_file: BenchFile, coreclr_name: Optional[str]) -> CoreclrAndName:
    return find_only_or_only_matching(
        lambda cn: cn.name, "--coreclr", coreclr_name, bench_file.coreclrs_and_names
    )


def get_config(bench_file: BenchFile, config_name: Optional[str]) -> FullConfigAndName:
    return find_only_or_only_matching(
        lambda cn: cn.name, "--config-name", config_name, bench_file.full_configs_and_names
    )


def get_benchmark(bench_file: BenchFile, benchmark_name: Optional[str]) -> BenchmarkAndName:
    return find_only_or_only_matching(
        lambda bn: bn.name, "--benchmark-name", benchmark_name, bench_file.benchmarks_and_names
    )


def try_find_benchfile_from_trace_file_path(path: Path) -> Optional[BenchFileAndPath]:
    parent = path.parent
    name = try_remove_str_end(parent.name, ".out")
    if name is None:
        return None
    else:
        assert name.endswith(".yaml")
        bench_path = parent.parent / name
        return parse_bench_file(parent.parent / name) if bench_path.exists() else None
